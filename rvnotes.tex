\documentclass{report}

\input{commands}

%\lhead{Left Header}
%\rhead{Right Header}

\begin{document}

% Change Font and Spacing
\large % change the font size to 12pt
\linespread{1.1} % change the line spacing

% Set the counter
\setcounter{section}{0}

\tableofcontents

\chapter{Introduction}

\section{Philosophy}

I am interested in ``observational'' mathematical finance.  I have
taken this terminology from Fernholz (2002), who regards ``classical''
mathematical finance as a normative theory.  For a long time, I
mistakenly saw this as the same dichotomy existing between psychology
and economics.  Psychology takes as its starting point the observation
of human behavior.  Theories follow observations, which are then
tested by experiments.  In this way, psychology is an empirical
discipline.  Mathematics does not play a prominent role in psychology
and psychologists are not searching for a unified theory of human
behavior.  Economics takes as its starting point how humans should
behave.  Care is taken to frame the theories that follow in
mathematical terms and to derive the consequences of behavior within
this formal system.  Fidelity to reality is less important than a self
contained theory.  I thought finance suffered the same flaws as
economics; however, the dichotomy in finance charts a different
divide.  To see this chasm we turn to probability and statistics.

Traditionally, the philosophical foundations of probabiltiy can be
divided between those that see probability as the manifestation of
repeatable ``random'' events and those that think probability
represents a state of knowledge.  My own view is that these two
perspectives reconcile and that the those interested in the former
interpretation prefer to study systems where one has \emph{knowledge}
that a random event happens repeatedly.  Thus the discrepency is
ultimately whether one does or does not have a certain piece of
knowledge.  In statistical terms, the question is whether one is
working with a stationary distribution or a distribution that changes
in time.  

One can methodically poke and prode a stationary system to divine its
inner workings.  The natural world appears to be stationary and
humanity has spent two millinea figuring out how it works. 
Unfortunately, it is not nearly as easy to examine financial systems.
It is unclear that such systems are stationary and hence one must
accept that it is unreasonable if not impossible to approach it as a a
physical system.  Consequently, ``How does this system function?'' is
of less immediate importance than ``How do I make decisions?''  The
two classical branches of mathematical finance--derivatives pricing
and portfolio optimization--are the mathematical answer to this
question.

Derivatives pricing tells one how to price an illiquid (that is
untraded) asset.  According to Derman, mathematical models are crude
representations of reality.  This poor approximation is a consequence
of the complexity of financial systems. Manufacturers of derivatives
have some interest in observational issues.  For instance, one would
like to find a model for stocks, bonds, and derivatives that matches
the distributions observed in the real world.  However, since one 
needs to calibrate a model to extract the information that will be
used to price a derivative, the most general framework may be too
vague.  Here we see how ``truth'' is less important than generating a
price.  Ultimately, one needs to sell something to make money.

Portfolio optimization tells one how to invest once one has settled 
upon an attitude to risk and a perspective on future returns. 
Unfortunately, neither of these quantities are easily determined. 
One's ``attitude to risk'' is more mythology than psychology--it
exists and makes sense in an abstract axiomatic world, but is detached
from observed human thought and behavior.  Furthermore, future returns
are hard to get a handle on because we lack the knowledge that
portfolio returns are generated by repeated random events.  Thus
portfolio optimization gives an individual a rigorous investment
strategy only after one has provided subjective input.

In both derivatives pricing and portfolio optimization one needs to
have a distribution for asset returns.  As mentioned above there does
not appear to be a historical trail of data from which one can
generate such a distribution.  Hence, the probabilities one assigns to
future prices will be ``subjective.''  This is the view of probability
taken by those that do not encounter repeated random events.  From
this perspective, one can interpret probability as an extended branch
of logic (Cox) or a coherent system of bets (De Finetti).  I believe
both perspectives make sense within the context of finance, where
one's logic must exclude the possiblity of entering into the wrong
side of an arbitrage.

To complicate matters, there appears to be some stationarity in
finance.  I would like to explore this avenue further.  Studying
realized volatility is an opportunity to learn about a quantity that
might display some stationairity.  Furthermore, it is a way to aquaint
myself with the statistical aspects of mathematical finance that one
needs in the real world.  I also need a numerical perspective for my
thesis, and I think statistics and econometrics provides the most
natural arena for computation in finance. 

\section{The Statistics of Finance}

Suppose we have simple model of stock price returns.  In particular,
let us suppose that the log an asset $S_t$ is driven by the dynamics
\[
d X_t = \log S_t = \mu dt + \sigma dW_t.
\]
By chosing these dynamics we are limiting ourselves to a class of
probability distributions characterized by two parameters, $\mu$ and
$\sigma$.  Let us assume further that the parameter $\sigma$ is known. 
This is unrealistic but not unreasonable since we can find good
estimates on $\sigma$.  We will justify this statement below.  Now
imaging that we observe the stock price at $N+1$ regularly spaced
times in the period $[0,T]$.  That is we will observe $X_{t_i}$ when
$t_i = \Delta i$ for $i = 0, \ldots, N$ and $\Delta = T/N$.  Then the
log return one will get from $t_{i-1}$ to $t_i$ is $R_{t_i} = X_{t_i}
- X_{t_{i-1}}$.  By the restrictions we have placed on the family of
distributions we consider the collection of $R_{t_i}$ are independent
and identically distributed as $\mcN(\Delta \mu, \sigma^2 \Delta)$. 
We want to estimate the parameter $\mu$ from the data we have
observed.  However, arriving at a good estimate for $\mu$ will require
quite a bit of patience.

\subsection{The Mean}

The problem is that when estimating $\mu$ the number of observations
we make is irrelevant to the accuracy of our approximation.  The
standard estimation procedure for independent and identially
distributed random variables is to arrive at an approximation using
the sample mean.  In particular, let
\(
\bar R = \frac{1}{N} \sum_{i=1}^N R_{t_i}.
\)
We know that $\bar R$ estimates the mean of the increment, which is
$\Delta \mu$ in our case.  Thus $\bar R / \Delta$, which we define to
be
\[
\hat \mu = \frac{1}{T}  \sum_{i=1}^N R_{t_i},
\]
will be an estimate of $\mu$.  If we expand this sum we get
\[
\hat \mu = \frac{R_T - R_0}{T} = \frac{\mu T + \sigma^2 W_T}{T} \sim
\mcN(\mu, \sigma^2 / T).
\]
Notice that this distribution \emph{does not depend} on the number of
observations $N$.  In othe words, the accuracy of our estimate does
not improve with more observations.  Hence $\hat \mu$ is not a
consistent estimate of $\mu$ as $N \ra \infty$.  It is a consistent
estimate of $\mu$ though as $T \ra \infty$.  It appears that we can
only wait and watch to get a good idea of the expected log return
$\mu$.  The natural question is, how long does one have to wait?

\subsection{A Bayesian Analysis}

From a Bayesian perspective, we do not have knowledge of the parameter
$\mu$ and hence I should model it using a probability distribution. 
We have already made the decision to parameterize the data we observe
as normal.  Hence the likelihood function $p(\hat \mu | \mu)$ will be
normal with variance $\sigma^2 / T$.  After chosing a prior
distribution for $\mu$ and observing the above data we arrive at a
posterior distribution for $\mu$ given by
\[
p(\mu | \hat \mu) \propto p(\hat \mu | \mu) p(\mu).
\]
This is written in ambiguous Bayesian notation where all the $p$'s
above are different functions and the variables of the density are the
same symbols as the random variables.  If we assume the improper and
uniformative prior $p(\mu) = 1$ then the posterior distribution for
$mu$ is
\[
p(\mu | \hat \mu) \propto \exp \Big( \frac{\mu - \hat \mu}{\sigma^2 /
T} \Big).
\]
Hence we get that the distribution of $\mu$ is $\mcN(\hat \mu,
\sigma^2 / T)$.  (Note the dual relatinoship between $\mu$ and $\hat
\mu$).  

Bayesians use ``credible intervals'' to describe how confident they
are in an estimation.  Suppose we want to find the 90\% symmetric
credible interval for the posterior distribution of $\mu$.  We know
the distribution of $\frac{\mu-\hat \mu}{\sigma / \sqrt{T}}$ is
$\mcN(0,1)$.  Using R we find that the cummulative distribution
function $\phi$ has $\phi(0.05) = -1.64$ and $\phi(0.95) = 1.64$. 
Thus the 90\% credible interval for $\mu$ is
\[
-1.64 \leq \frac{\mu-\hat \mu}{\sigma / \sqrt{T}} \leq 1.64.
\]
Rearranging we have that the error $\mu - \hat \mu$ needs to satisfy
\[
- 1.64 \times \frac{\sigma}{\sqrt{T}} \leq \mu - \hat \mu \leq 1.64
\times \frac{\sigma}{\sqrt{T}}.
\]
At last we can answer the question of how long it will take to get a
``good'' estimate of $\mu$.  Let us suppose that you are investing and
you want to be 90 \% sure that the absolute error between your
estimate of the mean return and its actual value are within $\pm 10
\%$.  Then you want your interval to be $-0.1 \leq \mu - \hat \mu \leq
0.1$  Thus to get that level of accuracy you will need to wait
\[
0.1 = 1.64 \times \frac{\sigma}{\sqrt{T}} \implies T = \big(
\frac{1.64 \sigma}{0.1} \Big)^2.
\]
I ran some R code to test different error tolerances.  The data
follows the yearly log prices of the S \& P for the last 60 years. 
The sample mean of this series is $0.06$ while the standard deviation
is $0.16$.  The results are below.  You can read the table as saying
``it would take T years for the 90 \% credible interval to be $[-$
tol, tol $]$.''

\begin{center}
\begin{tabular}{ c | c | c | c | c | c | c | c | c | c | c }
Error Tol & 0.01 & 0.02 & 0.03 & 0.04 & 0.05 & 0.06 & 0.07 & 0.08 &
0.09 & 0.10 \\ \hline
Years & 721 & 180 & 80 & 45 & 28 & 20 & 14 & 11 & 8 & 7
\end{tabular}
\end{center}

As you can it will take a while to get a grasp on $\mu$.  The problem
is that the error tolerance we have is on the order of the standard
deviations present.  We could have reprhased the error tolerance in
terms of standard deviations.  (In that case the time reduces to
something like $(1.64 \; / \textmd{ \# of stand dev })^2$.  Thus if we
want to keep our error within half a standard deviation at 90 \% we
still need to wait 11 years.  Normally when we perform experiments the
error in our instrument (standard deviation) is small compared to the
value that we measure.  In this case though the error in our
instrument is more than double what we are trying to measure (or so it
appears).

To give you some comparison of how bad that is, consider the age of
the universe.  According to Wikipedia, the universe is 13.73 billion
years old, with an uncertainty of 120 million years.  Thus the error
in the instrument measuring the age of the universe relative to the
size of the measurement is $120/13730 \sim 0.9 \%$.  For the stock
market, the error of the instrument (the S \& P 500) relative to the
size of the measurement is $0.16/0.06 \sim 267 \% $.  In this sense,
the S\&P is four orders of magnitude worse at measuring the drift of
its portfolio than NASA is at measuring the age of the universe; and
that is assuming the drift has been constant for the last 60 years.

One last note, if we do assume that the drift has not changed for the
past 60 years, then our table above suggests that we can say with 90\%
credibility that $\mu$ is within $\sim 0.03$ of the sample mean $0.6$. 
Thus it appears that we can say with some confidence that the log
returns of the S\&P are on the order of a percent. 

% The problem is that when I look on a finer partition
% the mean I try to estimate shrinks as well.  The mean
% scales perfectly with the partition size so that you
% do not gain any accuracy by making more observations.
% This contrasts with measuring something from a controlled
% experiement where the quantity we are trying to measure
% (\Delta \mu vs. \mu)
% \emph{does not} change with the number of measurements we
% are trying to take.

\subsection{The Variance}

You may recall at the beginning of this discussion that we claimed you
could take the variance to be known.  Clearly, though the variance for
the S \& P 500 is not known, so that may seem to be an unreasonable
assumption.  We could rectify that by using the standard error and a
$t$-distribution to estimate the credible intervals above.  Instead,
of doing that, let us justify that we can be confident in our
measurement of the standard deviation.  In particular, we will show
that the accuracy of our estimate increases with the frequency of our
observations.  

Imagine that the variance $\sigma^2$ is unknown.  We still will have a
parametric family of possible distributions for the log returns
$(R_{t_i})$.  The maximum likelihood estimator for the standard
deviation of $R_{t_i}$ is given by
\[
\frac{1}{N} \sum_{i=1}^N (R_{t_i} - \bar R)^2.
\]
We know that this random variable is a consistent estimator of
$\Var(R_{t_i}) = \sigma^2 \Delta$.  Dividing through by $\Delta$ we
get an estimator for the variance $\sigma^2$,
\[
\hat V = \frac{1}{N \Delta} \sum_{i=1}^N(R_{t_i} - \bar R)^2.
\]
It turns out that $\hat V$ is distributed as a $\chi^2$ R.V. with mean
$\frac{N-1}{N} \sigma^2$ and variance $\frac{2 \sigma^4}{N-1}$  Thus
for fixed time $T$, the estimator $\hat V$ is consistent for $N \ra
\infty$.  Thus sampling the log prices of our stock on a finer
partition will result in better estimates of $\sigma^2$.

Thus we like variance and volatility for several reasons.  First, it
is a value that can be estimated in short amounts of time.  Second,
the estimation improves as we gather data more quickly.  On a
philosophical level, realized volatility exploits the fact that high
frequency data will provide accurate estimates of ``uncertainty'' of a
process.  I put uncertainty in quotes here because there are several
measures of uncertainty.  For realized volatilty we are particularly
interested in measuring uncertainty by the fluctuations observed in
stock prices, i.e. in the quadratic variation of prices.

\section{Motivation}

That one can make such an approximation is financially useful as well as
mathematically interesting.  We consider a super-replication pricing
scheme in an incomplete market.  This construction will rely on the
the Black-Scholes pricing mechanism.  

To remind the reader, the Black-Scholes model consists of a money market
process $B_t$ and a stock process governed by Geometric Brownian
Motion,
\[
dS_t = S_t [ \mu dt + \sigma dW_t ].
\]
In this world, a contract in which I will pay you $f(S_T)$ dollars at
time $T$ costs you
\[
\bbE[ e^{-rT} f(e^{r T} S_0 e^{-\frac{1}{2} \sigma^2 T + \sigma Z}) ],
\hspace{12pt} Z \sim \mcN(0,1),
\]
at time $t = 0$.  We could rewrite this pricing functional as
\[
C(S_0, \sigma^2 T, r T)
\]
where
\[
C(s,V,R) = e^{-R} \bbE[ f(e^R s e^{-\frac{1}{2} V + \sqrt{V} Z}) ],
\hspace{12pt} Z \sim \mcN(0,1).
\]

Now let us consider a more general model.  Suppose we have a money
market account and a stock governed by
\[
dS_t = S_t [ \mu_t dt + \sigma_t dW_T ]
\]
where $(\mu_t)$ and $(\sigma_t)$ are adapted processes.  Pause for a
moment and appreciate the non-parametric quality of $S_t$.  The
Black-Scholes world forces us to believe the distribution of stock
returns is normal.  The model above allows for much wierder
distributions and consequently more ``realistic'' circumstances.  This
comes at a cost though.  We no longer can rely on replication or
completeness of the market to price a contingent claim.  Instead, we
can try to find a trading strategy that super-replicates the claim
$f(S_T)$.  

The following processes will be useful in our super-replication
strategy.  Let
\[
V_t = V_0 - \int_0^t \sigma_s^2 ds
\]
and
\[
R_t = R_0 - \int_0^t r_s ds.
\]  
I interpret $V_t$ and $R_t$ as measures of excess volatility and
excess risk free rate.  We will use the Black-Scholes functional to
arrive at a super-replication strategy.  In particular, the process
$X_t = C(S_t, V_t, R_t)$ super-replicates the contingent claim.

Notice that $\int_0^t \sigma_s^2 ds$ is our aforementioned integrated
volatility, which we can approximate using realized volatility.  Below
we will see that the initial values $V_0$ and $R_0$ are bounds upon
the integrated volatility and integrated short rate of return.  Of
course selecting such bounds, especially for $\int_0^T \sigma_s^2 ds$,
requires some statistical work.  This is one reason we care about the
distribution of realized volatility.

\begin{claim}
The process $(X_t)$ super-replicates the claim $f(S_T)$ in the
presence of no-arbitrage when $f$ is convex with $f(0) = 0$. 
Furthermore, $(X_t)$ can be synthetically constructed with the stock
and the bond.
\end{claim}

\begin{proof}
First, expand $X_t$ by Ito calculus.  In particular,
\begin{align*}
dX_t & = C_s dS_t + \frac{1}{2} C_{ss} dS_t^2 + C_V dV_t + C_r dR_t \\
& = \sigma_t^2 \Big[ \frac{1}{2} S_t^2 C_{ss} + C_V \Big] dt - C_R r_t
dt + C_s dS_t.
\end{align*}
Since $V_t$ and $R_t$ are of finite variation we do not need to worry
about their second order terms.  With a little effort one can show
that $\frac{1}{2} s^2 C_{ss} - C_V = 0$.  (You need to write the
expectation as an integral and then integrate by parts.)  Thus the
first term cancels and we are left with
\[
dX_t = - \frac{C_R}{B_t} \; dB_t + C_s \; dS_t.
\]
The process $(B_t)$ is the money market account.  Thus there is a
hedging strategy that replicates $X_t$.  The quantities $C_s(S_t,
\cdots)$ and $-C_R / B_t$ can be interpreted as the respective number
of stocks and bonds in one's portfolio.  Hence $S_t C_s(S_t, \cdots)$
is the total amount invested in the stock and $-C_R(S_t, \cdots)$ is
the total amount invested in bonds.  Furthermore, one can
differentiate $C$ and find that $s C_s - C_R = C$.  Given the
interpretation of these quantities above this shows that the summing
the amount invested in stock and the amount invested in bonds yields
the price of the synthetic secruity.  In other words, the
aforementioned portfolio is self-financing.

To see that this strategy super-replicates $f(S_T)$ we want to examine
the monotonicity of $C$ in $V$ and $R$.  Since $f$ is convex and $f(0)
= 0$ we have that $\alpha f(x/ \alpha) \geq f(x)$ for $\alpha \in
(0,1]$.  Thus when $R > 0$ 
\[
e^{-R} \bbE[ f(e^{R} \cdots) ] \geq \bbE[ f(\cdots) ].
\]
Hence we can take $R = 0$ and examine what happens in $V$ to get a
lower bound on $C$.  Recall that $C_V = \frac{1}{2} s^2 c_{ss}$.  The
convexity in $f$ ensures that $c_{ss} > 0$.  Thus $C_V > 0$ for all $V
> 0$ and we can conclude that $C$ is increasing for $V>0$.  This holds
for all $s, R \geq 0$ so we can conclude that
\[
\lim_{V \searrow 0} C(s, V, R) \geq \lim_{V \searrow 0} C(s,V,0) =
f(s).
\]
Hence $C(S_T, V_T, R_T) \geq f(S_T)$, which shows that our synthetic
security super-replicates $f(S_T)$.
\end{proof}

There are two ways in which realized volatility enters into this
super-replication procedure.  First, the process
\[
V_t = V_0 - \int_0^t \sigma_s^2 ds
\]
needs to be nonnegative.  Thus $V_0$ should be an upper bound for the
integrated volatility.  This quantity can be estimated by realized
volatility.  In particular, if one has a grasp on the distribution of
the realized volatility, then one can find a probabilistic upper bound
for the integrated volatility at time $T$.  Using this bound, one
would know what proportion of the time this super-replicating strategy
would work.  Second, when heding one trades $C_S(S_t, V_t, R_t)$ units
of stock at time $t$.  Realized volatility can be used to approximate
the quantity $V_t$.  In sum, realized volatility is needed for
estimating an upper bound on $V_T$ and for hedging.

\chapter{Modeling and Forecasting Realized Volatility}

The following discussion is based primarily on the work of Andersen et. al \cite{Andersen03}.  Let us recall a few observations about equity returns.  These observations carry over to other financial assets.  As the vocabulary suggests, one usually studies equity returns as opposed to equity prices.  It is most convenient to think in terms of $\log$ returns.  Thus we will contemplate quantities such as $LR_t = \log S_t$ where $S_t$ is the price of a stock.  One can then easily specify different periods on which to observe returns.  If time is measured in days, the daily log returns are given by $DLY_{t+1} = LR_{t+1}-LR_{t}$ whereas the weekly log returns are given by $LR_{t+7}-LR_{t}$.

If one starts to examine the daily log returns, for instance, he or she will find that the autocorrelation is zero for all leads and lags, suggesting that the daily returns are white noise.  The distribution of daily returns has more mass in its center and in its tails than the normal distribution.  Lastly, it appears that the volatiltiy of the daily log returns has some stickiness.  Times of high volatiltiy tend to persist as do times of low volatilty.  A measure of these fluctuations is the square of the daily log returns.  When calculating the sample autocorrelation this time series displays strong serial dependence.  This suggests that we should attempt to model the square of the daily log returns, since this time series has a richer description.

ARMA processes do not capture this range of phenomenon and consequently econometricians have developed several alternate time series models.  The GARCH family of models is the most well-known alternative method of modeling this phenomenon.  The basic idea behind the GARCH class of models is that the conditional variance or volatilty, given by $\sigma_t^2 = \bbE[DLY_t^2 | \mcF_{t-1}]$ follows some linear difference equation in $\sigma_{t-s}^2$ and $LR_{t-s}^2$.

Of course these models are confined to the realm of discrete time stochastic processes.  Financial mathematicians prefer continuous time models since, they are ammenable to stochastic calculus.  A class of continuous time models exists as well, called stochastic volatiltiy models\footnote{This name may be incorrect, or if it is not incorrect, it is at least misleading, since GARCH is most certainly a form of stochastic volatiltiy.}.  In these models, the log returns of stocks are governed by
\[
d \; DLY_t = \mu_t dt + \sigma_t dW_t
\]
where $\sigma_t$ is now governed by some dynamics
\[
d \; \sigma_t^2 = \textmd{ Right hand side of SDE }.
\]
This is the same idea as GARCH.  One is trying to specify the ``volatilty of volatiltiy.''  When attempting to calibrate these models one must inevitably discretize time and look and, for instance, the square of daily log returns.*

Closely related to the sqaure of log returns is the quadratic variation.  We will see that it is more natural to estimate and model this quantity in the presence of high frequency data than the daily returns.  (I need to add more here about the virtues of quadratic variation as a quantity.)

\section{Modeling}



\chapter{The Mathematics of Realized Volatility}

\section{Preliminaries}

For simplicity's sake, consider an Ito process
\[
X_t = \int_0^t \mu_s ds + \int_0^t \sigma_s dW_s.
\]
The quadratic variation of such a process is given by
\[
\quadvar{X}_t = \int_0^t \sigma_s^2 ds.
\]
The qunatity in the right hand side is refered to as the
\emph{integrated volatility}.  There are various ways to define
quadratic varation.  The definition above ensures that the quadratic
variation of $X_t$ is the increasing process $\quadvar{X}_t$, null at
time $t=0$, such that $X_t^2 - \quadvar{X}_t$ is a martingale. 
Equivalently the quadratic variation is the limit in probability of
\[
\sum_{\mcG} (X_{t_{i+1}} - X_{t_i})^2
\]
as the partitions $\mcG$ shrink to zero.  This gives rise to two
important observations
\begin{enumerate}
\item the quadratic varation is a measure of ``randomness'', that is
the magnitude of the fluctuations in process movements;
\item the quadratic varation can be (almost) observed.
\end{enumerate}
If we think of $X_t$ as the log returns a stock price process, then we
will, in fact, observe $(X_t)$ whenever a trade occurs.  Hence we can
compute
\[
\sum_{\mcG} (X_{t_{i+1}} - X_{t_i})^2
\]
for a specific partition.  Since stock trades occur with high
frequency the partition one observes in the real world should be quite
fine and hence the approximation given above should be close to
$\quadvar{X}_t$.  Of course we need to make these statements more
precise, but this will more or less be the case.  These notes are
taken from Per Mykland.

(This is from before I rearranged some content.)
Now that we have seen that integrated volatility and hence realized
volatility are useful quantities we want to examine how they are
related.  In particular, we want to study the various ways in which
realized volatility converges to integrated volatility.  The following
is a recreation of notes by Per Mykland.

To make our lives easier we will consider a local martingale which
takes the form of an Ito process,
\[
X_t = X_0 + \int_0^t \sigma_s dW_s.
\]
If we are in a financial or economic setting we could think of $X_t$
as the log returns on a stock governed by a stochastic volatiltiy
model.  Drift can be inserted into this model at the cost of a little
extra work.  The process $\sigma_s$ needs to satisfy some regularity
conditions.  For more on these regularity conditions consult
Banrndorff-Nielsen and Shephard, Estimating Quadratic Variation Using
Realized Volatility.  In this paper the ``spot volatility'' is assumed
to be stochastically independent of the underlying Brownian motion and
to have pathwise local bounded variation.  Mykland uses a different
set of criteria on $\sigma_s$.

Let $\mcG = (t_0, t_1, \cdots, t_n)$ be a partition of the interval
$[0,T]$ and let $t* = \max \{ t_i \in \mcG : t_i \leq t \}$.  We will
be rather relaxed with notation.  In particular, $\mcG$ will usually
refer to a partition, but not necessarily the same exact partition.  
\emph{Realized volatility} is the sum of squares approximation to the
quadratic variation of a process.  The realized volatility for the
partition $\mcG$ at time $t$ is
\[
[X,X]^{\mcG}_t = \sum_{t_{i+1} \in \mcG} (X_{t_{i+1}} - X_{t_i})^2 +
(X_{t} - X_{t^*})^2.
\]
In the real world we observe some random partition of time.  For now
though we will assume that we observe time on a deterministic grid. 
From the properties of quadratic variation we know that the realized
volatility is a consistent estimator of the integrated volatility. 
Taking the limit in probability, that is
\[
\lim_{|\mcG| \ra 0} \; [X,X]^{\mcG}_t = \int_0^t \sigma_s^2 ds.
\]
We would like to understand how fast this convergence takes place.  In
other words, we would like to find some sort of central limit theorem. 
Ideally, for very fine partitions, the normalized difference between
the realized volatility and the integrated volatility would be
normally distributed.  We will see that a result similar to this
holds.  In particular,
\[
\sqrt{n} \Big([X,X]^{\mcG^n}_t - \int_0^t \sigma_s^2 dt \Big) \convlaw
\mcN(0,1) \times \textmd{Scale}
\]
where the scale is some random variable, increasing in time and
independent of $\mcN(0,1)$.  It will require quite a bit of work to
get to this point.  Here is an impressionistic version of the
statement we would like to prove so that the reader may view the
direction we are headed and glimpse the logic behind the path we take.

\vspace{12pt} \noindent
\textbf{Quasi-Theorem}: If the error between the realized volatiltiy
and integrated volatility, call it 
\(
M^{(n)} =  [X,X]^{\mcG^n}_t - \int_0^t \sigma_s^2 dt,
\)
converges in probability to some process,
\begin{equation}
\label{hypothesis}
n [M^{(n)},M^{(n)}]_t \convprob \textmd{ some process },
\end{equation}
then the normalized error converges in law to a mixed Gaussian,
\begin{equation}
\label{conclusion}
\sqrt{n} M^{(n)} \convlaw \mcN(0,1) \times \textmd{Scale},
\end{equation}
where the scale is some random variable, increasing in time and
independent of $\mcN(0,1)$.

\vspace{10pt} \noindent
In what follows, we first establish that the hypothesis above holds,
and then we will state and prove the rigorous version quasi-theorem. 
There are several flurishes one can consider for this problem.  Due to
market microstructure stock price returns do not behave like
semimartingales.  One can overcome this problem by considering
realized volatility on a courser grid, for instance, by observing
stock prices every five minutes.  Equities are traded with high enough
frequency that we can consider such a grid deterministic.  Thus
traditionally, researchers have looked at equally spaced,
deterministic grids.  Mykland considers the case when observation
times are random.  In this case one may, theoretically, use all the
data available to estimate realized volatility.  But it should be
noted that this is purely theoretical as market microstructure
contaminates the high frequency observations.

\vspace{10pt} \noindent \textbf{Terminology:}  The reader may be
intersted to know that realized volatilty goes by several names.  It
is also refered to as the realized variance.  In this case, realized
volatiltiy refers to the square root of realized variance.

\subsection{The Error Process}

To makes this treatment a bit more rigorous.  Let $\mcG^n$ be a
partition with $n$ components.  The error process for the $n$th
partition is given by
\[
M^{(n)}_t =  \sum_{t_{i+1} \in \mcG^n} (X_{t_{i+1}} - X_{t_i})^2 +
(X_{t} - X_{t^*})^2 - \int_0^t \sigma_s^2 ds.
\]
Most of the time the $n$ will be supressed on both $\mcG^n$ and
$(M_t^{(n)})$.  We chose the letter $M$ to denote the error process
because $M$ is, in fact, a local martingale.  To see this apply Ito's
formula to $(X_t - X_{t_i})^2$ to get
\[
(X_t - X_{t_i})^2 = 2 \int_{t_i}^t (X_s - X_{t_i}) dX_s + \int_{t_i}^t
\sigma_s^2 ds.
\]
Using this fact at the partition points $t_{i+1}$ we have
\[
M_t = 2  \sum_{t_{i+1} \in \mcG} \int_{t_i}^{t_{i+1}} (X_s - X_{t_i})
dX_s + 2 \int_{t^*}^t (X_s - X_{t^*}) dX_s.
\]
Thus $(M_t)$ is a local martingale as $(X_t)$ is a local martingale. 

We can think of $M_t$ as the error accruing in our estimate at we
evolve in time.  This quantity can be decomposed into the error
accrued on each interval of time.  To that end define
\[
M^{i,n}_t : = (X_{t} - X_{t_{i-1}})^2 - \int_{t_{i-1}}^t \sigma_s^2 ds
\textmd{ when } t_{i-1} < t \leq t_{i}
\]
and $M^{i,n}_t = 0$ otherwise.  Thus $(M^{i,n}_t)$ records the error
along the $i$th interval.  When an observation at time $t_i$ is made
we start reset the tracking of our error centered at $X_{t_i}$.  This
decomposition ensures that
\[
M^{(n)}_t = \sum_{i=1}^n M^{i,n}_t,  \;\; [M^{(n)},M^{(n)}]_t =
\sum_{i=1}^n [M^{i,n} ,M^{i,n}]_t, 
\]
and
\[
d M^{i,n}_t = (X_t - X_{t_{i-1}}) \1_{(t_{i-1},t_i]} d X_t, \;\;\;\;
M^{i,n}_0 = 0.
\]

We will eventually show that the quadratic variation of the error
process converges in probability.  Before we get to that, a short
digression is necessary to set up the way in which quadratic variation
will converge, followed by a discussion of the relationship between
quadratic variation of the error and higher order fluctuations of the
martingale $X_t$.

% $M^i_t$ - the error on the ith interval

\subsection{Stochastic Order Symbols}

For notational convenience we introduce the idea of stochastic order
symbols, which are analogous to the order symbols found in analysis. 
In particular, for a sequence of random variables we say that
\[
Z_n = o_p(1) \textmd{ if for all } \epsilon > 0, \lim_n \bbP(|Z_n|
\geq \epsilon) = 0,
\]
and
\[
Z_n = O_p(1) \textmd{ if for all } \epsilon > 0 \textmd{ there exists
} M > 0 \textmd{ such that } \bbP(|Z_n| \geq M) < \epsilon.
\]
The first statement declares that $(Z_n)$ converges in probability
while the second statement declares that $(Z_n)$ is bounded in
probability.  Sometimes we will care how a sequence of random
variables behaves relative to some other quantity $u_n$, which could
be random or nonrandom.  In this case we have
\[
Z_n = o_p(u_n) \textmd{ if } Z_n / u_n = o_p(1),
\]
and
\[
Z_n = O_p(u_n) \textmd{ if } Z_n / u_n = O_p(1).
\]
Both notations are closed under addition and scalar multiplication. 
Thus we know that $X_n = o_p(1)$ and $Y_n = o_p(1)$ imply that $X_n +
Y_n = o_p(1)$.  In a proof this fact might be used to write something
like 
\[
X_n + Y_n = X_n + o_p(1) = o_p(1) + o_p(1) = o_p(1).
\]
We also know that if we have a sequence $(a_n)$ which eventually
dominates $(b_n)$ that $X_n = o_p(a_n)$ and $Y_n = o_p(b_n)$ imply
that $X_n + Y_n = o_p(a_n)$.  Thus $o_p(a_n) + o_p(b_n) = o_p(a_n)$. 

\subsection{$r$-ticity}

In what follows, the fluctuations in the mesh size will play a key
role in determining convergence.  These fluctuations enter the picture
through a convenient recursive relationship between the error process
$(M_t)$ and the underlying process $(X_t)$.  To see this we need to
define the \emph{realized quarticity} of the process $(X_t)$ on the
partition $\mcG$ by
\[
[X;4]_t^\mcG = \sum_{t_{i+1} \leq t} (X_{t_{i+1}} - X_{t_i})^4 + (X_t
- X_{t^*})^4.
\]
As before we may supress the superscript $\mcG$.  This quanitity is
asymptotically proportional to the quadratic variation of $M_t$, which
is precisely the relationship we are looking for since we want to show
that $[M,M]_t$ converges in probability.

Thinking in terms of $dM_t = (X_t - X_{t_i}) dX_t$, observe that the
quadratic variation of the error process is
\[
[M,M]_t = 4 \sum_{t_{i+1} \leq t} \int_{t_i}^{t_{i+1}} (X_s - X_t)^2
d[X,X]_s + 4 \int_{t^*}^t (X_s - X_{t^*})^2 d[X,X]_s.
\]
We can also arrive at the quantity $(X_t - X_{t_i})^2 d[X,X]_t$ by Ito
differentiation of $(X_t - X_{t_i})^4$, a term in the sum of realized
quarticity.  In particular,
\[
d (X_t - X_{t_i})^4 = 4(X_t - X_{t_i})^3 dX_t + 6 (X_t - X_{t_i})^2
d[X,X]_t.
\]
Summing over the partition and subsitituting what we have for the
quadratic variation of $M_t$ along with the definition of realized
quarticity we see that
\[
[X;4]^\mcG_t = N^{(n)}_t + \frac{3}{2} [M^{(n)},M^{(n)}]_t
\]
where the martingale term
\[
N^{(n)}_t =
\sum_{t_{i+1} \leq t} 4 \int_{t_i}^t (X_t - X_{t_i})^3 dX_t +  4
\int_{t^*}^t (X_t - X_{t^*})^3 dX_t.
\]
This term can be thought of as the ``error of the
quadratic-variation-of-the-error and the realized quarticity.''  You
might need to ponder that statement for a moment.  We show below that
this term is $o_p(n^{-1})$, which ensures the convergence we seek. 
The proof that you will see relies on one more iteration of this
recursive relationship.

In particular, we want to consider the quadratic variation of $(N_t)$
and relate it to the fluctuations of $(X_t)$.  Since $(N_t)$ is a
stochastic integral we know its quadratic variation is given by
\[
[N,N]_t = 16 \sum_{t_{i+1} \leq t} \int_{t_i}^{t_{i+1}} (X_s -
X_{t_i})^6 d[X,X]_s + 16 \int_{t^*}^{t} (X_s - X_{t^*})^6 d[X,X]_s.
\]
Repeating the same trick as above we introduce the \emph{realized
ochticity} of the process $(X_t)$ on the partition $\mcG$ by
\[
[X;8]^\mcG_t = \sum_{t_{i+1} \leq t} (X_{t_{i+1}} - X_{t_i})^8 + (X_t
- X_{t^*})^8.
\]
Taking the Ito differential of a term of the realized ochticity yields
\[
d(X_t - X_{t_i})^8 = \underbrace{8 (X_t - X_{t_i})^7
dX_t}_{\textmd{martingale term}} + 28 (X_t - X_{t_i})^6 d[X,X]_t.
\]
Summing this over $i$ and substituting $[N,N]_t$ for the finite
variation term gives us 
\[
[X;8]^\mcG_t = \textmd{ martingale term } + \frac{28}{16}
[N^{(n)},N^{(n)}]_t.
\]

\subsection{Quadratic variation of the normazlied error}

Now we return to showing that the hypothesis of the quasi-theorem
stated above is satisfied by a reasonalby large class of models.  As
discussed above, we want to show that the quadratic variation of the
normalized error process, $n [ M^{(n)}, M^{(n)}]$, converges in
probability.  One can study this convergence under several different
assumptions on the volatility process and the sampling times.

We took the time in the previous section to study quadratic variation
since it is related to variance.  In particular, we know that
$E(M_t^2) = E([M,M]_t)$ for a martingale $(M_t)$.  Thus if you can
control the quadratic variation you can control the variance of a
process.  We will strengthen this idea slighly by observing that the
variance of the supremum of a process can be controlled by its
quadratic variation.  

\begin{theorem}
A modified version of Doob's Maximal inequality tells us that for a
martingale $(M_t)$
\[
\bbE \Big( \sup_{0 \leq s \leq t} |M_s|^2 \Big) \leq 4 \bbE \Big(
[M,M]_t \Big).
\]
\end{theorem}

This type of statement, relating the supremum process to quadratic
variation, can be strengthened yet again by the Burkholder-Davis-Gundy
inequality.  

\begin{theorem}
For a continuous martingale $(M_t)$ we have
\[
c_P \bbE \Big( [M,M]_t^{p/2} \Big) 
\leq \bbE \Big( \sup_{0 \leq s \leq t} |M_t|^p \Big)
\leq C_P \bbE \Big( [M,M]_t^{p/2} \Big).
\]
\end{theorem}

These inequalities can be used to establish uniform convergence in
probability.   To see this, take for the moment $(Y^{(n)}_t)$ to be an
arbitrary sequence of martingales.  There are three steps to showing
that $(Y^{(n)}_t)$ converges, which can be summarized as 1) Chebychev,
2) Burkholder-Davis-Gundy, and 3) control the quadratic variation.  
In particular, the quantity $\bbP( \sup |Y^{(n)}_t| > \delta) \leq C
\bbE( \sup |Y^{(n)}_t|^2)$ by Chebychev's inequality.  This in turn
satisfies $\bbE( \sup |Y^{(n)}_t|^2) \leq C \bbE[Y^{(n)},Y^{(n)}]$ by
Burkholder-Davis-Gundy.  (The constant $C$ here depends on $\delta$.) 
Thus if one has control of the quadratic variation
$[Y^{(n)},Y^{(n)}]$, then one has uniform control in probability. 
This is the basic outline for the proof of the proposition to follow.

\vspace{10pt} \noindent \textbf{Standing Assumptions}
\begin{enumerate}
\item There is some non-random constant $\sigma_+^2$ so that
\[
\sigma_t^2 \leq \sigma_+^2 \textmd{ for all } t.
\]
\item The partition $\mcG_n$ on $[0,T]$ has $n+1$ points and is
nonrandom or independent of the process $(X_t)$.
\item The fluctuations of the partition are controlled according to
$\displaystyle \sum_{t_{i+1} \in \mcG^n} (t_{i+1} - t_i)^3 =
O_p(n^{-2})$.
\end{enumerate}

\begin{proposition}
If the standing assumptions are satisfied and $(\mcG_n)$ is a sequence
of deterministic partitions with $|\mcG_n| = o_p(1)$, then
\[
\sup_{0 \leq t \leq T} | \; [M^{(n)},M^{(n)}]_t - \frac{2}{3}
[X;4]^{\mcG_n}_t \; | = o_p(n^{-1}).
\]
\end{proposition}

\begin{proof}
Recall that we defined the error of the
quadratic-variation-of-the-error with the quarticity as
\[
N^{(n)}_t =  [M^{(n)},M^{(n)}]_t - \frac{2}{3} [X;4]^{\mcG_n}_t .
\]
We want to show that $n N^{(n)}_t$ is $o_p(1)$.  (The superscript is
supressed in what follows.)  As discussed earlier, we will do this by
gaining control of the quadratic variation of $(n N_t)$.  To that end,
in the development of ochticity we saw that
\[
[N,N]_t = \frac{4}{7}[X;8]^{\mcG}_t + \textmd{ martingale term }.
\]
Thus taking the expectation of both sides we have that
\[
\bbE [N,N]_t = C \: \bbE [X;8]^\mcG_t.
\]
($C$ will play the role of a generic constant in this proof.)  
Since $X_t - X_{t_i}$ is a martingale for $t > t_i$ we can apply the
Burkholder-Davis-Inequality with $p=8$ to show that
\[
\bbE \; \sup_{t_i \leq t \leq t_{i+1}} |X_t - X_{t_i}|^8  \leq C \:
\bbE \; ( \:[X,X]_{t_{i+1}} - [X,X]_{t_i} \: )^4.
\]
Summing over the entire partition we have
\[
\bbE^* [X;8]^\mcG_t \leq C \: \sum_{t_{i+1} \leq t} \bbE \; (
\:[X,X]_{t_{i+1}} - [X,X]_{t_i} \: )^4 + C \: \bbE \; ( \:[X,X]_{t} -  
[X,X]_{t^*} \: )^4 .
\]
Recall at this point that the quadratic variation of $(X_t)$ is $\int
\sigma^2_s ds$ and that $\sigma_s^2$ is bounded by $\sigma_+^2$ to see
that
\[
( \:[X,X]_{t_{i+1}} - [X,X]_{t_i} \: )^4 \leq \sigma_+^8 ( t_{i+1} -
t_i)^4.
\]
Hence the expectation of the realized ochticity is bounded by
\[
C \sum_{t_{i+1} \leq t} ( t_{i+1} - t_i)^4 + C ( t - t^*)^4
\]
and we conclude that
\[
n^2 \bbE [N,N]_t \leq C \: n^2 \: \sum_{t_{i+1} \leq t} \bbE (  
t_{i+1} - t_i)^4 + C \: n^2 \: \bbE \; ( t - t^*)^4 .
\]

We need to find a way to bound the above expectation.  Obviously, the
assumptions we have imposed on our propositions ensure that this
quanitity goes to zero as $n$ goes to infinity, though this relies on 
a clever trick.  

Observe that the above bound holds when evaluated at a stopping time. 
In particular, let $\epsilon, \delta > 0$ and define the stopping time
$\tau_n$ by
\[
\tau_n := \inf \{ t :  C \: n^2 \sum_{t_{i+1} \leq t} \bbE \; (
t_{i+1} - t_i)^4 + C \: n^2 \: \bbE \; ( t - t^*)^4 > \epsilon
\delta^2 \}.
\]
In this case we have the bound on the fluctuations of our paritions by
\begin{equation}
\label{quarticity-proof-bound}
C \: n^2 \sum_{t_{i+1} \leq \tau_n} \bbE \; ( t_{i+1} - t_i)^4 + C \:
n^2 \bbE \; ( \tau_n - t^*)^4 \leq \epsilon \delta^2.
\end{equation}
Now that we have the desired bound, we can implement our Chebychev-BDG
program with one small alteration:
\begin{align*}
\bbP( n \sup_{0 \leq t \leq T} |N_t| > \delta) 
& \leq \bbP(n \sup_{0 \leq t \leq \tau_n} |N_t|) + \bbP(\tau_n \neq T)
&  \\
& \leq \frac{C}{\delta^2} \: \bbE \; \Big( n \sup_{0 \leq t \leq
\tau_n} |N_t| \Big)^2 + \bbP(\tau_n \neq T) & \textmd{Chebychev} \\
& \leq \frac{C}{\delta^2} \: n^2 \: \bbE \; [N,N]_{\tau_n} +
\bbP(\tau_n \neq T) & \textmd{BDG} \\
& \leq \epsilon + \bbP(\tau_n \neq T) & \textmd{ by
(\ref{quarticity-proof-bound}).}
\end{align*}
The assumptions we put upon the partition assure us that
\[
n^2 \sum_{t_{i+1} \leq t}( t_{i+1} - t_i)^4 +  n^2 ( t - t^*)^4 \leq
|\mcG_n| \Big(n^2 \sum_{t_{i+1} \leq t}( t_{i+1} - t_i)^3 +  n^2 ( t -
t^*)^3 \Big)
\]
converges to zero in probability.  Thus $\lim_{n \ra \infty}
\bbP(\tau_n \neq T) = 0$.  Hence taking the limit as $n$ goes to
infinity yields
\[
\lim_{n \ra \infty} \bbP ( n \sup_{0 \leq t \leq T} |N^{(n)}_t| >
\delta) \leq \epsilon.
\]
As $\epsilon$ was arbitrary we are done: $N^{(n)}_t = o_p(n^{-1})$.

\end{proof}


From our Quasi-Theorem we know that the first property we need to
establish is that $n [M^{(n)},M^{(n)}]_t $ converges in probability to
some process.  This process will be related to the ``Asymptotic
Quadratic Varation of Time'' (AQVT) defined by
\[
H_t = \lim_{n \ra \infty} \frac{n}{T} \sum_{t_{i+t} \in \mcG^n}
(t_{i+1} - t_i)^2.
\]
To this point we have thought of the partition $\mcG^n$ as
deterministic.  But as the definition of AQVT suggests we want to work
with random partitions.  Let us state some standing assumptions for
this section so that we need not repeat them.

\begin{proposition}
Assume that the standing assumptions of this section hold and that the
AQVT exists.  Then
\[
n[M^{(n)},M^{(n)}]_t \convprob \int_0^t \sigma_s^4 dH_s.
\]
\end{proposition}


\subsection{A limit theorem for realized volatility}

We have seen that the hypotesis of our quasi-theorem hold for the
types of models we are interested in.  Now we will rigorously state
the limit theorem from which our quasi-theorem is devised.  In order
to understand how this limit theorem works we must digress to discuss
compact, seperable metric spaces.  Before we make this digression, let
us state the theorem.

\begin{theorem}
\label{thelimittheorem}
Let $(M^{(n)}_t)$ be a sequence of continuous local martingales on
$[0,T]$, each adapted to $(\mcF_t)$ and centered at zero.  Suppose
that there is an $\mcF_t$-adapted process $f_t$ such that
\[
[M^{(n)},M^{(n)}]_t \convprob \int_0^t f_s^2 ds \; \textmd{ for } t
\in [0,T],
\]
and that for each $i = 1, \ldots , p$,
\[
[M^{(n)}, W^{(i)}]_t \convprob 0 \; \textmd{ for } t \in [0,T].
\]
Then there is an extension $(\mcF'_t)$ of the filtration $(\mcF_t)$
and an $(\mcF'_t)$-adapted martingale $M_t$ so that $M^{(n)}_t$
coverges stably to $(M_t)$.  Furthermore, this process is
characterized as a stochastic integral in $(\mcF'_t)$ by
\[
M_t = \int_0^t f_s dW_s',
\]
where $(W_t')$ is a Brownian Motion.
\end{theorem}

Painting in broad strokes, we first need to establish that the
quadratic variation of $(M^{(n)}_t)$ is tight.  (Tightness is a
compactness property.)  This will then imply that $(M^{(n)}_t)$ is
tight.  From this tightness, we can extract a limit point $(M_t)$ of
$(M^{(n)}_t)$.  

As mentioned above this sketch hides lots of details.  Most of the
work underlying the proof has to do with establishing tightness for
semimartingales.  Thus to familiarize the reader with some of these
concepts we present an introduction below.

\section{Compactness of Stochastic Processes}

When we study probability we encounter several forms of convergence. 
For a sequence of random variables $(X_n)$, we could examine almost
sure convergence, convergence in $L_2$, convergence in probabilty, and
convergence in law.  Mathematically speaking these different forms of
convergence induce different topologies on the underlying space of
random variables.  Roughly speaking, larger topologies have more
rigorous terms for convergence.  Thus as a topology gets smaller it is
easier for objects to converge.  The cost for this ease comes in the
form of precision of error.  For intsance, if I know that the sequence
$(X_n)$ converges to $X$ uniformly, then I know that eventually $X_n$
will within a constnat distance from $X$ everywhere.  However, if I
only know that $X_n$ converges to $X$ in $L_2$, then it may be the
case that for all $w \in \R$ there is a subsequence so that
$X_{n_k}(w)$ is always at least one unit away form $X_{n_k}(w)$.

Often this tradeoff is worthwhile since ease of convergence
facilitates compactness.  We care deeply about compactness because it
helps us greatly when examing sequences of random variables.  Since we
will be working with metric spaces, compactness ensures that a well
behaved sequence of random variables will have a convergent
subsequence.

The compactness properties we study will be similar in character to
the Arzela-Ascoli theorem, which is a statement regarding the
compactness of a set of functions.  In particular, if $A$ is a subset
of continuous functions mapping $[a,b]$ into the reals, then $A$ is
compact under the uniform norm if and only if $A$ is closed, bounded,
and equicontinuous.  A set of functions is equicontinuous if at each
point $x$, the functions in $A$ have a ``uniform'' amount of
continuity.  In particular, for any $\epsilon > 0$, there is a
universal $\delta>0$ so that $|f(y)-f(x)|<\epsilon$ whenever $f \in A$
and $|x-y|<\delta$.  The utility of Arzela-Ascoli is to transfer
questions of compactness into more familiar terms.  For Arzela-Ascoli
compactness translates into closedness, boundedness, and
equicontinuity.  For probability measures, compactness is transferred
to \emph{tightness}.  Tightness is a property that prevents the mass
of a measure from escaping to infinity.

\subsection{Some Terminology}

Given a sequence of random variables $(X_n)$ mapping into $\R$, we can
induce a measure on $\B$ by $\mu_n(B) = \bbP(X_n \in B)$ for all $B
\in \B$.  The measure $\mu_n$ is called the \emph{law} or
\emph{distribution} of $X_n$.  We say that the the law $\mu_n$
\emph{converges weakly} to $\mu$ and write $\mu_n \RA \mu$ if
\[
\int f(x) \mu_n(dx) \ra \int f(x) \mu(dx) \hspace{12pt} \textmd{ for
all bounded and continuous } f. 
\]
We say that $X_n$ \emph{converges in distribution (or in law)} to $X$
and write $X_n \convlaw X$ if the distribution of $X_n$ converges
weakly to the distribution of $X$.  When $X_n$ maps into $\R$, we can
also define the \emph{cumulative distribution function} $F_n(x) =
\mu_n( (-\infty,x])$.  The CDF $F_n$ converges to $F$ at all points of
continuity of $F$ if and only if $\mu_n$ converges to $\mu$.

\subsection{Compactness for distributions on $\R$}

The cumulative distribution functions leads naturally to notions of
campactness for probability measures.  Suppose that one has a
collection of CDF's $(F_n)$, but does not know whether the sequence
converges.  We do know that the cumulative distribtion functions are
all bounded by $[0,1]$ for each point $x \in \R$.  By the compactness
present in the real numbers, for each $x \in \R$, we can find a
subsequence so that $F_{n_k}(x)$ converges.  

Using this basic property on the rational numbers, one can find a
right continuous, increasing function $F$ which is the limit of
$F_{n_k}$ at all points of continuity of $F$.  When the mass of $F_n$
does not escape to $-\infty$ or $+\infty$ we know the limit $F$ will
be a CDF as well.  This is the criterion we call tightness.  In terms
of the distributions, if we can find a sequence of compact sets for
which $\mu_n$'s mass is uniformly contained and tending towards zero,
that is if $(\mu_n)$ is tight, then $F$ will be a cumulative
distribution function.  

From this CDF we can recover a distribution $\mu$ so that $\mu_n$
converges to $\mu$ weakly.  Thus tightness is the property that
ensures a sequence of probability measures is compact under weak
convergence.  (See Billingsley's Probability and Measure for details.)

\subsection{The Abstract Setup}

The compactness properties described above for distributions on the
real numbers can be generalized to a more abstract framework.  Instead
of considering the real numbers, consider a complete, seperable metric
space $E$ with \sigalg $\mcE$, which is the Borel \sigalg generated by
the open sets associated with our metric.  Let $\mcP(\mcE)$ denote the
set of all probability measures on $\mcE$.  We endow $\mcP(\mcE)$ with
the weak topology, that is the topology for which $\mu \mapsto \mu(f)$
is a continuous function for all bounded continuous $f : E \mapsto
\bbR$.  Here $\mu(f) = \int_E f(e) \mu(de)$.  If $\mu_n$ converges
weakly to $\mu$, denoted by $\mu_n \RA \mu$, then $\mu_n(f) \ra
\mu(f)$ for all bounded and continuous functions $f$.  As mentioned
earlier, notions of compactness for subsets of $\mcP(\mcE)$ are
transfered to notions of tightness.  To make this explicit we state
the definition and then the theorem.

\begin{definition}
A subset $A \subset \mcP(\mcE)$ is \emph{tight} if for all $\epsilon >
0$ there exists a compact set $K$ in $E$ such that $\mu(E \setminus K)
\leq \epsilon$ for all $\mu \in A$.  We say that a collection of
random variables is tight if the corresponding collection of
distributions is tight.
\end{definition}

\begin{theorem}
A subset $A$ of $\mcP(\mcE)$ is relatively compact (in the weak
topology) if and only if it is tight.  Relative compactness means that
given a sequence of measures $\mu_n$ in $A$, there exists a
subsequence $\mu_{n_k}$ that converge to some element of $\mcP(\mcE)$. 
Thus if $A$ is closed and tight under the weak topology, then it is
compact. 
\end{theorem}

\subsection{Arzela-Ascoli for Stochastic Processes}

Let us step back for a moment and examine where we are going.  Recall
that we are interested in the convergence of stochastic processes. 
Stochastic processes are not measures so we will be looking for a way
to connect a stochastic process indirectly to tightness.  Ultimately,
this will produce a characterization of compactness for a set of
stochastic processes just like Arzela-Ascoli is a characterization of
compactness for a set of functions.

A stochastic process can be viewed as a random variable.  In
particular, we can think of a stochastic process as a map from
$\Omega$ into a space of functions.  When the stochastic process has
continuous paths this space of functions is $\bbC(\R^d)$, the space of
all continuous functions mapping $\R_+$ into $\R^d$.  When the
stochastic process has jumps this space of functions is $\bbD(\R^d)$,
the space of all right continuous left limit (RCLL) functions mapping
$\R_+$ into $\R^d$.

As we discussed above a random variable $X$ on $(\Omega, \mcF, \bbP)$
has a distribution $\mu$ generated by $\mu(A) = \bbP(X \in A)$. 
Refering to our abstract framework, we are interested in distributions
on complete, seperable metric spaces.  Thus we are intersted in random
variables which map $\Omega$ into a complete, seperable metrics space
$E$, since $\mu$ will then be a measure on $\mcE$.  In the context of
stochastic processes we have $\Omega$ mapping into $\bbC(\R^d)$ or
$\bbD(\R^d)$.  Thus we want to find a metric on $\bbC(\R^d)$ or
$\bbD(\R^d)$ rendering the space complete and seperable.

\subsubsection{Continuous Stochastic Processes}

When the stochastic processes under consideration are continuous we
can view them as random variables mapping $\Omega$ into $\bbC(\R^d)$. 
It turns out that the local uniform topology, which says that the
sequence of functions $(\alpha_n)$ converges to zero whenever
\[
\sup_{0 \leq s \leq t} |f_n(s)| \ra 0 \textmd{ for all } t \in \R_+,
\]
can be described by a metric that renders $\bbC(\R^d)$ complete and
seperable.  From our discussion above we know that a collection of
distributions $(\mu_n)$ on $\bbC(\R^d)$ is relatively compact under
this topology if an only if $(\mu_n)$ is tight.  Furthermore,
tightness can be reduced to a sort of ``probabilistic Arzela-Ascoli.''  
To understand this theorem, we to construct some measure of
equicontinuity.  For an element of $\bbC(\R^d)$ we associate a modulus
of continuity over the interval $I$ by
\[
w(\alpha; I) = \sup_{s,t \in I} |\alpha(s) - \alpha(t)|,
\]
and a modulus of continuity over over intervals of length $\theta$ on
the interval $[0,N]$ by
\[
w_N(\alpha, \theta) = \sup \{ w(\alpha; [t, t+\theta] : 0 \leq t <
t+\theta \leq N\}.
\]
Now we are ready to state our ``probabilistic Arzela-Ascoli.''

\begin{theorem}
The sequence of random variables $(X^n)$ is tight if and only if
\begin{enumerate}
\item For bounded time intervals, the collection of stochastic
processes is ``uniformly bounded in probability.''  In other words,
for all $N \in \bbN$ and $\epsilon > 0$ there are $n_0$ and $K$ such
that
\[
\bbP^n \Big(\sup_{t \leq N} |X_t^n| > K \Big) \leq \epsilon \;\;\;
\textmd{ for } n \geq n_0.
\]
\item For bounded time intervals, the colletion of stochastic
processes is ``equicontinuous in probability.'' In other words, for
all $N \in \bbN$, $\epsilon > 0$, and $\eta > 0$ there are $n_0$ and
$\theta$ such that
\[
\bbP^n \Big( w_N(X^n,\theta) > \eta \Big) \leq \epsilon \;\;\;
\textmd{ for all } n \geq n_0.
\]
\end{enumerate}
\end{theorem}

Now that we have a criterion for tightness, all questions of
compactness of continuous stochastic processes can be refered back to
our ``probabilistic Arzela-Ascoli.''  As a sidenote, the above proof
relies on a version of Arzela-Ascoli for $\bbC(\R^d)$ to establish the
sufficient condition, reminding us of the importance of convient
formulations of compactness.

\subsubsection{Stochastic Processes with Jumps}

Continuous sample paths are a good starting point when examing
compactness and establishing a probabilistic version of Arzela-Ascoli. 
The local uniform topology has an intuitive meaning and understandable
metric; showing that the space of continuous functions is seperable
and complete under this metric is not too difficult; and studying this
space provides insight into the procedures needed for allowing jumps. 
However, the technical details of finding a probabilistic version of
Arzela-Ascoli for stochastic processes with jumps are much more
challenging.  In fact, Jacod and Shiryaev recommend skipping over the
construction of a metric on $\bbD(\R^d)$.  We will follow that advice
except to say that there is a metric on $\bbD(\R^d)$ that makes
renders this space complete and seperable.  The interested reader can
find more information in J \& S's Limit Theorems for Stochastic
Processes or Billengsley's Convergence of Probability Measures.

Since $\bbD(\R^d)$ is a complete, seperable metric space we know that
a collection of measures on $\bbD(\R^d)$ are relatively compact if and
only if the collection of measures is tight.  As with continuous
sample paths, tightness can be reduced to a probalistic version of
Arzela-Ascoli dealing with the boundedness and equicontinuity of the
stochastic processes.  

The ``equicontinuity'' condition we will see relies on a different
``modulus of continuity'' than the continuous case.  In particular, we
define the modulus of continuity up to time $N$ on a partition of at
least size $\theta$ for a RCLL function $\alpha$ as
\[
w'_N(\alpha,\theta) = \inf \Big\{ \max_{i \leq r} w(\alpha; [t_{i-1},
t_i)) \; : \; 0 = t_0 < \cdots < t_r = N, \; \inf_{i<r} (t_i -
t_{i-1}) \geq \theta \Big\}.
\]
This modulus of continuity makes sense because RCLL functions are
somewhat well behaved.  In particular, RCLL functions have at most
countably many jumps.  This suggests that $w'$ measures continuity on
those portions of $\alpha$ that are continuous.  This is almost the
case except that jumps can ``bunch up'' near a point and hence $w'$
measures the modulus of continuity at that point as well.  This could
be a problem.  For instance, the function
\[
\alpha(t) = \sum_k (-1)^k \1_{[2^{-k},2^{-k+1})}(t)
\]
is right continuous and oscillates with increasing frequency $t$
approaches zero.  Under the metric defined above we would always have
a modulus of continuity greater than $1$.  However, the function
defined above does not have a left limit.  The requirement that left
limits exist will force oscillations that ``bunch up'' to also have
smaller jump sizes and hence some sense of ``continuity'' as bestowed
by $w'$.   Now that we have a modulus of continuity for $\bbD(\R^d)$,
we can state the probabilistic version of Arzela-Ascoli for stochastic
processes with jumps.

\begin{theorem}
The sequence of random variables $(X^n)$ mapping into $\bbD(\R^d)$ is
tight if and only if
\begin{enumerate}
\item For bounded time intervals, the collection of stochastic
processes is ``uniformly bounded in probability.''  In other words,
for all $N \in \bbN$ and $\epsilon > 0$ there are $n_0$ and $K$ such
that
\[
\bbP^n \Big(\sup_{t \leq N} |X_t^n| > K \Big) \leq \epsilon \;\;\;
\textmd{ for } n \geq n_0.
\]
\item For bounded time intervals, the colletion of stochastic
processes is ``$\bbD$-equicontinuous in probability.'' In other words,
for all $N \in \bbN$, $\epsilon > 0$, and $\eta > 0$ there are $n_0$
and $\theta$ such that
\[
\bbP^n \Big( w'_N(X^n,\theta) \geq \eta \Big) \leq \epsilon \;\;\;
\textmd{ for all } n \geq n_0.
\]
\end{enumerate}
\end{theorem}

We can now refer all questions regarding compactness of stochastic
processes with jumps back to our new and improved ``probabilistic
version of Arzela-Ascoli.''  We can think of this characterization as
\emph{the definition} of tightness (or relative compactness) for
stochastic processes, though much work goes into constructing and
establishing this fact.  The proof of this theorem is managable and
can be found in Chapter VI of J \& S for the intersted reader.  The
most convoluted portion of this entire process is developing the
metric on $\bbD(\R^d)$.  Unfortunately, this is just the tip of the
iceberg for tightness and stochastic processes.  J \& S spend four
chapters discussing alternate characterizations of tightness and
applying tightness to show convergence of stochastic processes in a
variety of settings.  In particular, J \& S move from limit theorems
involving processes with independent increments to limit theorems
involving a general class of semimartingales.  This takes three entire
chapters.  We will not summarize the aforementioned material, but
rather refer to it when needed, setting forth the appropriate theorems
when necessary.

\subsection{Stable Convergence}

We have one last concept to discuss before proceeding to the proof of
our limit theorem.  Recall that weak convergence of random variables
is apothetic to the underlying probability spaces on which those
random variables are defined.  Consider a sequence of random variables
$(X_n)$ defined on $(\Omega_n, \mcF_n, \bbP_n)$.  Weak convergence of
$(X_n)$ takes place a common codomain, $E$, which we take to be a
complete seperable metric space.  The distribution of $X_n$ is defined
by $\mu_n(A) = \bbP(X_n \in A)$ for all $A \in \mcE$.  The sequence
$\mu_n$ is obvlivious to the specific structure of the probability
spaces $(\Omega_n, \mcF_n, \bbP_n)$.  Once one has pulled back to the
distribution $\mu_n$ that information is forgotten, specifically the
information encoded in the \sigalg $\mcF_n$.  However, sometimes we
want to keep track of that information.

Suppose for a moment that you now have a sequence of random variables
$(X_n)$ on a common probability space $(\Omega, \mcF, \bbP)$ and a sub
\sigalg $\mcG \subset \mcF$.  We want to look at the the weak
convergence of $(X_n)$ taking into account the information stored in
$\mcG$.  To simplify let us assume $X_n$ maps into the reals.  We want
to make sure that the distribution of $X_n$ when one has the
information $\mcG$.  In particular, we want
\[
\bbP(X_n \leq x, A) \ra \bbP(X \leq x, A) \;\;\; \textmd{ for all } A
\in \mcG.
\]
This can be stated in terms of the distribution of $X_n$ conditioned
on $A$ as well.  In general terms we have the following:

\begin{definition}
Let $(X_n)$ be a sequence $\mcF$ measurable random variables and
$\mcG$ be a sub \sigalg of $\mcF$.  Then $(X_n)$ converges
\emph{$\mcG$-stably} in law to $X$ if $X$ is measurable with respect
to an extension of $\mcF$ so that for all $A \in \mcF$ and all bounded
and continuous $f$, 
\[
\bbE \Big[ \1_A f(X_n) \Big] \ra \bbE \Big[ 1_A f(X) \Big].
\]

\end{definition}

Notice that the above equation is saying the same thing as the
heursitic definition.  We simply chose $f$ so that it converges to a
characteristic function.  Were we to then apply the monotone class
theorem, this definition essentially says that $X_n$ converges jointly
in law with all $\mcG$ measurable random variables.  

As Aldous explains, stable in law convergence is the property of a
sequence of random variables \emph{not} a property of the distribution
of random variables.  A simple example differentiating convergence in
law from stable converge in law is the following.  Suppose $X$ and
$X'$ are independent and identically distributed.  Let $X_n$ be $X$
when $n$ is odd and $X'$ when n is even.  Clearly, $(X_n)$ converges
in law to $\mcL(X) = \mcL(X')$.  However, $(X_n)$ does not converge
$\sigma(X)$-stably in law to $X$.

\section{Proving A Limit Theorem for Realized Volatility}

To remind the reader, we want to prove the following:  Let
$(M^{(n)}_t)$ be a sequence of continuous local martingales on
$[0,T]$, each adapted to $(\mcF_t)$ and centered at zero.  Suppose
that there is an $\mcF_t$-adapted process $f_t$ such that
\[
[M^{(n)},M^{(n)}]_t \convprob \int_0^t f_s^2 ds \; \textmd{ for } t
\in [0,T],
\]
and that for each $i = 1, \ldots , p$,
\[
[M^{(n)}, W^{(i)}]_t \convprob 0 \; \textmd{ for } t \in [0,T].
\]
Then there is an extension $(\mcF'_t)$ of the filtration $(\mcF_t)$
and an $(\mcF'_t)$-adapted martingale $M_t$ so that $M^{(n)}_t$
coverges stably to $(M_t)$.  Furthermore, this process is
characterized as a stochastic integral in $(\mcF'_t)$ by
\[
M_t = \int_0^t f_s dW_s',
\]
where $(W_t')$ is a Brownian Motion.

\begin{proof}
As stated earlier we will not prove every aspect of this proof.  The
theorems from J \& S that we use will not be exact replications from
those found in the text, but rather rephrased versions that fit the
suppositions at hand.  The results we will establish relies on several
incarnations of tightness and stable convergence.  An important
\textbf{assumption} that we will make is that $(\mcF_t)$ is gerenated
by a $p$-dimensional Brownain Motion.

On the most basic level, this proof relies on compactness, that is to
say tightness.  We want to show that $(M_n)$ converges in some way to
the proces $M$.  We will do this by showing that every subsequence of
$M_n$ has a further subsequence with a limit point, as justified by
tightness.  We go on to show that this limit point does not depend on
the subsequence we started with.  In other words, every
sub-subsequence converges to the same limit point.  This establishes
convergence to $M$.

We begin with the quadratic variation of the error process $M^n$. 
Theorem VI.3.37 of J \& S states that if the continuous, increasing
process $X^n$ converges to the continuous, increasing process $X$ in
finite dimensional law then $X^n$ converges in law on $\bbD(\R)$ to
$X$.  Regarding the quadratic variation, we know that $[M^n,M^n]$ is a
continuous increasing process that converges in probability to a
continuous increasing process at each moment in time.  Thus the finite
dimensional distributions of $[M^n,M^n]$ converges to the finite
dimensional distributions of $\int f_s^2 ds$.  Hence Theorem VI.3.37
implies that $[M^n,M^n]$ converges to $\int f_s^2 ds$ in law in
$\bbD(\R)$.   Thus we know i) that the expectation of $[M^n,M^n]$ is
locally bounded and hence $M^n$ is a locally square integrable
martingale and ii) that $[M^n,M^n]$ converges in law in $\bbD(\R)$,
which implies that $[M^n,M^n]$ is tight. 

Instead of looking at subsequences of $(M^n)$ we want to look at
subsequences of \\ $(W^1, \ldots, W^p, M^n)$ so that we may use stable
convergence.  (Recall that the filtration $(\mcF_t)$ is generated by
the $p$-dimensional Brownian motion.  Thus showing that we have
tightness of $(W^1, \ldots, W^p, M^n)$ will ensure that $M^n$
converges $\mcF_T$-stably in law.)  To show that we have tightness for
this multidimensional random variable, we need to show that the sum of
the quadratic variation of each component is tight.  In particular, we
need J \& S Theorem VI.4.13.  This theorem roughly states:  Suppose
$(X^n)$ is a sequence of continuous, locally square integrable
martingales with $X^n_0 = 0$.  Then 
\[
(X^n) \textmd{ is tight if } \sum_{j \leq d} [X^{n,j},X^{n,j}]
\textmd{ is tight.}
\]
In our case this sum is equal to $pt + [M^n,M^n]_t$.  Applying Theorem
VI.3.37 again we have that $(p \cdot + [M^n,M^n]_\cdot)$ is tight. 
Thus the continuous, locally square integrable martingale $(W^1,
\ldots, W^p, M^n)$ is tight.

Now consider an aribtary subsequence $(n_k)$.  By tightness there is a
further subsequence $n_{k_l}$ so that $(W^1, \ldots, W^p,
M^{n_{k_l}})$ converges in law to $(W^1, \ldots, W^p, M)$ where $M$ is
as of yet unspecified.  We will rewrite $n_{k_l}$ as just $n$ to
simplify notation.  Theorem IX.1.17 of J \& S states: Let $W$ be a $p$
dimensional process and let $(M^n)$ be a sequence of continuous, local
martingales; if $(W,M^n)$ converges in law to $(W,M)$, then $M$ is a
local martingale with respect to the filtration generated by $(W,M)$. 
Hence the limit point $M$ we found earlier is a local martingale with
respect to the filtration $(\mcG_t)$ generated by $(W,M)$.  Thus we
have show that $M^n$ converges $\mcF_T$-stably in law to $M$.  

A proposition from Mykland states that if a sequence of continuous
local martingales $(M^n)$ that converges $\mcF_T$-stably in law to
$M$, then the joint random variable $(M^n, [M^n,M^n])$ converges
$\mcF_T$-stably in law to $(M,[M,M])$.  Looking at the marginal
distribution of this law we must have that $[M,M]_t = \int_0^t f_s^2
ds$ in law.  This means that $[M,M]_t$ is a continuous stochastic
process.  (J \& S take a filtration to be right continuous by
definition.  Thus the filtration we are working with can tell if a
process is continous at any time $t$.  Thus if we ask the question,
``find me the $\omega$ so that $\int_0^t f_s^2(\omega) ds$ is
continuous up to time $t$'' we will get a set of probabilty one. 
Hence $[M,M]_t$ must also be continuous up to time $t$ with
probability $1$.  I may need to refine this argument.)  Since $[M,M]$
is continuous we may conclude that $M$ is continuous.

Perhaps at this point you may see in what direction we are headed. 
Since $M$ is continuous it is ammenable to a host of tricks we find in
continuous time stochastic processes.  In particular, we will be able
to use some clever techniques from Levy.  Define $W'_t = \int_0^t 
f^{-1}_s dM_s$.  By the assumption that $[M^n,W^i] \convprob 0$ we
know from stable convergence that $[M,W^i] = 0$ for $i = 1, \ldots,
p$.  Thus $[W'_t,W^i_t] = 0$, $[W'_t, W'_t] = t$, and we may conclude
by Levy that $(W_t,W'_t)$ is a $p+1$ dimensioanl Brownian motion with
respect to the filtration $(\mcG_t)$.  (If $(f_t)$ is zero on a set of
positive measure we need to adjust our technique.)  By construction $M
= \int_0^t f_s dW'_s$.  

Notice that the joint law of $(W^1,\ldots,W^p,M)$ is independent of
the subsequence $(n_k)$.  Thus for any subsequence $(n_k)$ there is a
further subsequence $(n_{k_l})$ so that $M^{n_{k_l}}$ converges
$\mcF_T$-stably in law to $M$.  Since all subsubsequences have the
same limit point we may conclude that $M^n$ converges stably in law to
$M$.  (See the Corollary to Theorem 25.10 in Billingsley if you want
to justify the last sentence.)
\end{proof}

\section*{An application with real data}

The algorithms
  -TAQ
  -how to break up data
    -difficulty in doing this
  -use higher frequency data
  -total variation grows
  -graph
  -does not appear to converge
  -this would suggest that returns are not semi-martingales?
  --this is wrong - Mihai suggested that this doesn't really
  ---tell us anything
  -are prices semimartingales?
     -stochastic integration needs semimartingales
  -shiryeav - R/S test
  -long horizon returns look more normal (i think?)

\section*{Two-Scales Realized Volatility}

As we saw above the quadratic variation appears to converge when one
samples data at the highest frequency.  Mykland, et. al interpret this
to mean that stock prices are not semimartingales.  This raises a
philosophical question.  What exactly is the price of a stock.  Above
we took the price of the stock to be the average of the bid and the
ask price.  But one could arrive at alternate interpretations.  Karel
Janecek has suggested that one needs to see the entire order book to
arrive at the price of a stock.  Though he admits that a decent
approximation of the price of a stock is the harmonic average of the
bid price and the ask price weighted by the shares available at the
bid price and the shares available at the ask price.  We defer an in
depth discussion of ``price'' at this point and start to explore a
practical path.

One way to reconcile that observed prices are not semimartingales is
to assume that some error accrues each time one measures the price of
a stock, that is each time a stock is traded.  In this setting the
``true'' price of a stock is a semimartingale $(X_t)$; however,
whenever one measures this price, by observing a trade, there is some
measurement error $\ep_{t_i}$.  Thus the ``price'' that is measured is
\[
Y_{t_i} = X_{t_i} + \ep_{t_i}.
\]
We will assume that the observation error is pairwise independent,
identically distributed, and independent of $X_t$.  This point of view
will produce a rather complete narrative of how one should go about
approximate realized volatility.  What follows is a very close
replication of what can be found in ``A Tale of Two Time Scales:
Determining Integrated Volatility with Noisy High-Frequency Data'' by
Zhang, Mykland, and Ait-Sahalia (2005).  

Zhang et. al attribute the observation error to market microstructure
noise.  For instance, prices fluctuate depending on whether one buys
or sells stock, since there is a bid price and an ask price. 
Furthermore, the bid and ask prices are misleading when submitting a
market order since there may not be enough depth at the current bid or
ask price to fill and order.  For instance, if one submits a market
order to buy 5 shares of stock, and the current ask price is only for
two shares and the next lowest ask price is for three shares, then one
will pay the weighted average of current ask price and the next lowest
ask price.  These two concerns are the tip of the market
microstructure iceberg.  We will defer a discussion of microstructure
and simply model these collective phenomenon as ``observation error.''

Zhang et. al's analysis takes place within setting of a continuous Ito
process
\[
dX_t = \sigma_t dW_t.
\]
A few definitions are in order.  We will be working with \emph{partitions} or \emph{grids} of the real number line.  Thus a partition is an increasing sequence of real numbers $\mcG = \{ t_0, \ldots, t_n \}$.  Often we will refer to some subgrid of $\mcH \subset \mcG$.  The size of a grid is given by 
\[
|\mcH| = \{ \textmd{\# of points in } \mcH \} - 1.
\]
Sometimes the grids we work with will be deterministic, but often we will have random grids, which correspond to the random times at which stocks trade.  The realized quadratic variation of a semimartinagle $Z$, given the grid $\mcH$ is denoted and defined by
\[
[Z,Z]^\mcH_t = \sum_{t_j \in \mcH : t_j < t} (Z_{t_{j,+}}-Z_{t_j})^2.
\]
Here $t_{j,+}$ is the next element greater than $t_j$ in $\mcH$.  Now we can being to examine various estimates of the quadratic variation in the presence of microstructure noise.

\subsection{Sampling on one time scale}

Zhang and associates rank five different approaches one can take to
estimating realized volatility.  The ``fifth-best'' estimate is to
take the naive approach and calculate the realized volatilty as if no measurement error had occured.  If $\mcG$ is the partition of the
observed prices this would correspond computing
\[
[Y,Y]^{(all)} = \sum_{t_i \in \mcG} (Y_{t_i} - Y_{t_{i-1}})^2.
\]
Here $(all)$ represents the entire grid of observations.  If one expands this out he or she finds that
\[
[Y,Y]^{(all)} = [X,X]_T^{(all)} + 2 [X,\ep]_T^{(all)} + [\ep,\ep]_T^{(all)}.
\]
We are thinking of $\ep_t$ as some point process here.
Assuming that there are $n$ gridpoints in $\mcG$ the error associated
with this estimate is
\[
2 n \bbE \; \ep^2 + O_p(n^{1/2}).
\]
A more specific asymptotic statement is that
\[
n^{-1/2} \Big( [Y,Y]^{(all)}_T - 2 n \bbE \ep^2 ) \ra_\mcL 2 (\bbE \ep^4)^{1/2} Z_{noise},
\]
where noise is a standard normal random variable.  The subscript indicates that this quantity converges to the error generated by the microstructure noise.

The above asymptotic statement shows that the microstructure noise dominates the approximation error.  In fact, the microstructure noise is so great, that one fails to approximate the quadratic variation at all.  In other words, one does not even arrive at an estimate of the integrated volatility
$\int_0^t \sigma^s ds$.  \emph{However, one could use this estimate to
measure the variance of the observation error.}  This is an important
observation for two future discussions.  First, as noted above, stock
prices are not semimartingales.  As a result Mandelbrot and others
have suggested using fractional processes to model stock prices.  We
hope to find a link between calibration of fractional prices to stock
data and observation error encountered when measuring realized
volatility.  Second, when trading in the real world one must account
for the fact that the price one is quoted is not necessarily the price
one pays.  This is encapsulate in the observation error.  Thus if one
can estimate the distribution of observation error accurately, then
one can incorporate this statistic into models of derivative pricing
or portfolio optimization.  (Aside: perhaps one can use measures such
as quarticity to approximate higher order moments of $\ep_t$.)

Econometricians recognized that this naive approach was flawed from
the beginning.  The solution, which persists today, is to sample the
stock data at some lower frequency, marginalizing the impact of
observation error.  For instance, one might sample stock prices every
five minutes even though data arrives on the order of seconds.  The
``naive'' version of this approach is to subsample at some arbitrarily
chosen frequency, such as five minutes.  Zhang et. al refer to this as
the ``fourth best'' approach to estimating realized volatility.

To understand the asymptotic results we proceed with an example. 
Suppose one wants to look at realized volatility over a one day
period.  The New York Stock Exchange opens at 9:30 a.m. and closes at
4 p.m. giving us a 6.5 hour trading day.  If a trade occurs every
second on average, this gives a total of 23,400 trades in a day. 
Since there are 300 seconds in 5 minutes, sampling every 5 minutes
means that we would include every 300th observation, which gives rise
to a total of $n_{sparse} = 78$ observations in a day. 
Asymptotically, as the number of observations increases and
$n_{sparse}$ scales with the increasing number of observations we have
\begin{displaymath}
\begin{split}
[Y,Y]_T^{(sparse)} & =_{\mcL} \ip{X}{X} + 2 n_{sparse} \bbE \ep^2 \\
& + 
\Big[ 
\underbrace{
  \underbrace{4 n_{sparse} \bbE \ep^4}_{\textmd{ due to noise }} 
  + 
  \underbrace{\frac{2T}{n_{sparse}}  
    \int_0^T \sigma_t^4 dt}_{\textmd{ due to discretization }}
}_{\textmd{ total variance }}
\Big]^{1/2} Z_{total}.
\end{split}
\end{displaymath}
Here $Z_{total}$ is a standard normal random variable.

Improving upon this ``sparse method,'' Zhang et. al propose the
``thrid best'' approach, which is to chose a subsampling frequency
that minimizes the mean squared error of the estimate.  You will notice that there the analysis of the fourth best estimate simply choses an arbitrary $n_{sparse}$.  The third best method is simply an analysis of which is the best $n_{sparse}$ to chose.

\subsection*{Using Two Time Scales}

The ``second best'' method encapsulates the two time scale approach.  Recall that the subsampling method avoided the overwhelming error induced by microstructure noise by sparse subsampling.  However, this throws away lots of data.  There are two main ideas in the two time scale approach.  First, let's consider how we might make use of all the data.  When we subsample, we look at every $K$th piece of data.  But this throws away the $K-1$ pieces of data in between.  Furthermore, there is no guid as to whether we should start this subsampling at the first data point, the second data point, or the $K-1$th data point.  To rectify these two issues, we can think about generating $K-1$ different subsampled estimates.  The first estimate corresponds to starting at the first data point, the second at the second data point, up to the $K-1$ estimate starting at the $K-1$ data point.  We then take those $K$ estimates and average them.  This is a good idea because averaging tends to reduce error.  In this sense, using all the data will be helpful.

Asymptotically, we have that
\[
[Y,Y]_T^{(avg)} = \ip{X}{X}_T + 2 \bar n \bbE \ep^2 + \xi Z_{total}
\]
where
\[
\xi^2 = \underbrace{4 \frac{\bar n}{K} \bbE \ep^4}_{\textmd{noise}} + \underbrace{\frac{T}{\bar n} \eta^2}_{\textmd{discretization}}.
\]
The quantity $\bar n$ is approximately the ratio of the number of points in the entire grid to how often we subsample, that is, $\bar n \sim n / K$.  The quantity $\eta^2$ is a measure of how erratic the stock price and observation times are.  The quantity $\bar n$ diverges in the limit, thus this estimate, like the previous three, is biased.

Aside: The quantity $\eta^2$ is given by
\[
\eta^2 = \frac{4}{3} \int_0^t \sigma_t^4 H_t dt.
\]
The process $H_t$ is the asymptotic quadratic variation of time that we encountered above.  It measures the time irregularity of stock trades.

To rectify this bias, we look at the ``first best'' estimate.  Notice that $\bbE \ep^2$ is a quantity we can estimate using the ``fifth best'' method.  Thus we can use the realized variation over the entire partition to remove the bias in our ``second best'' estimate.  In particular, recall that
\[
\widehat{\bbE \ep^2} = \frac{1}{2n} [Y,Y]_T^{(all)}
\]
estimates $\bbE \ep^2$.  Looking at the second best estimate we see that we need to remove $2 \bar n \bbE \ep^2$.  Thus we get the first best estimation of the quadratic variation of $X$ by subtracting that amount using our fifth best estimate:
\[
\widehat{\ip{X}{X}} = [Y,Y]_T^{(avg)} - \frac{\bar n}{n} [Y,Y]^{(all)}_T.
\]
Asymptotically speaking, we have
\[
n^{1/6} \Big( \widehat{\ip{X}{X}}_T - \ip{X}{X}_T \Big)
\ra_\mcL \Big( \frac{8}{c^2} (\bbE \ep^2)^2 + c \eta^2 T \Big)^{1/2} \mcN(0,1)
\]
where $c$ is some constant.  Now one can see where the term ``two time scales'' comes from.  Our estimate consists of two pieces, one piece is based on (relatively) ``low'' frequency sampling while the other is based on ``high'' frequency sampling.

\subsection{Further developments}

These ideas can be extended to multi-scales sampling where one includes even more time scales in the realized volatility estimation of quadratic variation.  One can also extend this work by assuming some sort of dependency within the microstructure noise.  For instance, the microstructure noise might be an AR(1) process as opposed to white noise.  This appears to be the case in some stock data.  For more on dependent microstructure noise see \cite{ait-sahalia08}.

\bibliography{rvnotes}{}
\bibliographystyle{plain}

\end{document}
